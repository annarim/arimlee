{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO0+xBi153ZZVthWxFqTbw9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/annarim/arimlee/blob/main/%EC%98%A4%ED%94%88%EC%86%8C%EC%8A%A4_%EA%B3%BC%EC%A0%9C3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "whK5kN0njay0",
        "outputId": "594eee6f-663d-4d36-880e-b372cca83923"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "id": "FPibtUuWhVtd",
        "outputId": "a0bd95f1-1e4c-4799-aadc-6af2ac0027e1"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-1bef834c4eb0>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mkmnist\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m#KMNIST 읽어들이기\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: cannot import name 'kmnist' from 'tensorflow.keras.datasets' (/usr/local/lib/python3.10/dist-packages/keras/api/_v2/keras/datasets/__init__.py)",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import kmnist\n",
        "\n",
        "#KMNIST 읽어들이기\n",
        "(x_train, t_train),(x_test, t_test) = kmnist.load_data()\n",
        "print(x_train.shape, x_test.shape) #훈련데이터,테스트 데이터 모양 출력, 28x28의 손으로 쓴 문자 이미지가 6만 장\n",
        "\n",
        "#각 픽셀의 값을 0~1의 범위에 넣는다\n",
        "x_train = x_train/255\n",
        "x_test = x_test/255\n",
        "\n",
        "#손으로 쓴 문자 이미지를 1개 표시\n",
        "plt.imshow(x_train[0].reshape(28,28), cmap=\"gray\")\n",
        "plt.title(t_train[0])\n",
        "plt.show()\n",
        "\n",
        "#1차원으로 변환\n",
        "x_train = x_train.reshape(x_train.shape[0],-1)\n",
        "x_test = x_test.reshape(x_test.shape[0],-1)\n",
        "print(\"훈련용 데이터의 형태:\", x_train.shape, \"테스트용 데이터 형태:\", x_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#VAE 각 설정\n",
        "epochs = 10\n",
        "batch_size = 128\n",
        "n_in_out = 784   #입출력층의 뉴런 수\n",
        "n_z = 2   #잠재 변수의 수(차원 수)\n",
        "n_mid = 256   #중간층의 뉴런 수\n",
        "\n",
        "#모델 구축\n",
        "from tensorflow.python.keras.models import Model\n",
        "from tensorflow.python.keras import metrics   #평가 함수\n",
        "\n",
        "from tensorflow.python.keras.layers import Input, Dense, Lambda\n",
        "from tensorflow.python.keras import backend as K   #난수의 발생에 사용\n",
        "\n",
        "#잠재 변수를 샘플링하기 위한 함수\n",
        "def z_sample(args):\n",
        "  mu, log_var = args   #잠재 변수의 평균값과 분산의 대수\n",
        "  epsilon = K.random_normal(shape=K.shape(log_var), mean=0, stddev=1)\n",
        "  return mu + epsilon * K.exp(log_var/2)   #Reparametrization Trick에 의해 잠재 변수를 구한다\n",
        "\n",
        "#Encoder\n",
        "x = Input(shape=(n_in_out,))\n",
        "h_encoder = Dense(n_mid, activation=\"relu\")(x)\n",
        "mu = Dense(n_z)(h_encoder)\n",
        "log_var = Dense(n_z)(h_encoder)\n",
        "z = Lambda(z_sample, output_shape=(n_z,))([mu, log_var])\n",
        "\n",
        "#Decoder\n",
        "mid_decoder = Dense(n_mid, activation=\"relu\")  #뒤에서 사용\n",
        "h_decoder = mid_decoder(z)\n",
        "out_decoder = Dense(n_in_out, activation=\"sigmoid\")  #뒤에서 사용\n",
        "y = out_decoder(h_decoder)\n",
        "\n",
        "#VAE의 모델을 생성\n",
        "model_vae = Model(x,y)\n",
        "\n",
        "#손실 함수\n",
        "eps = 1e-7  #log 안이 0이 되는 것을 막는다\n",
        "rec_loss = K.sum(-x*K.log(y+eps)-(1-x)*K.log(1-y+eps))/batch_size  #재구성 오차\n",
        "\n",
        "reg_loss = -0.5*K.sum(1+log_var-K.square(mu)-K.exp(log_var))/batch_size #정칙화 항\n",
        "vae_loss = rec_loss+reg_loss\n",
        "\n",
        "model_vae.add_loss(vae_loss)\n",
        "model_vae.compile(optimizer=\"adam\")\n",
        "model_vae.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I6Nr8r1JhZYg",
        "outputId": "972c1c66-6eda-4c1d-cfc6-e5adfeb57026"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 784)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 256)          200960      input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 2)            514         dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 2)            514         dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "lambda (Lambda)                 (None, 2)            0           dense_1[0][0]                    \n",
            "                                                                 dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 256)          768         lambda[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "dense_4 (Dense)                 (None, 784)          201488      dense_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "tf.math.subtract_1 (TFOpLambda) (None, 784)          0           dense_4[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add (TFOpLambd (None, 784)          0           dense_4[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_1 (TFOpLam (None, 784)          0           tf.math.subtract_1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_2 (TFOpLam (None, 2)            0           dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "tf.math.square (TFOpLambda)     (None, 2)            0           dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "tf.math.negative (TFOpLambda)   (None, 784)          0           input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "tf.math.log (TFOpLambda)        (None, 784)          0           tf.__operators__.add[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf.math.subtract (TFOpLambda)   (None, 784)          0           input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "tf.math.log_1 (TFOpLambda)      (None, 784)          0           tf.__operators__.add_1[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "tf.math.subtract_3 (TFOpLambda) (None, 2)            0           tf.__operators__.add_2[0][0]     \n",
            "                                                                 tf.math.square[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.math.exp (TFOpLambda)        (None, 2)            0           dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "tf.math.multiply (TFOpLambda)   (None, 784)          0           tf.math.negative[0][0]           \n",
            "                                                                 tf.math.log[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "tf.math.multiply_1 (TFOpLambda) (None, 784)          0           tf.math.subtract[0][0]           \n",
            "                                                                 tf.math.log_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.math.subtract_4 (TFOpLambda) (None, 2)            0           tf.math.subtract_3[0][0]         \n",
            "                                                                 tf.math.exp[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "tf.math.subtract_2 (TFOpLambda) (None, 784)          0           tf.math.multiply[0][0]           \n",
            "                                                                 tf.math.multiply_1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "tf.math.reduce_sum_1 (TFOpLambd ()                   0           tf.math.subtract_4[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "tf.math.reduce_sum (TFOpLambda) ()                   0           tf.math.subtract_2[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "tf.math.multiply_2 (TFOpLambda) ()                   0           tf.math.reduce_sum_1[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf.math.truediv (TFOpLambda)    ()                   0           tf.math.reduce_sum[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "tf.math.truediv_1 (TFOpLambda)  ()                   0           tf.math.multiply_2[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_3 (TFOpLam ()                   0           tf.math.truediv[0][0]            \n",
            "                                                                 tf.math.truediv_1[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "add_loss (AddLoss)              ()                   0           tf.__operators__.add_3[0][0]     \n",
            "==================================================================================================\n",
            "Total params: 404,244\n",
            "Trainable params: 404,244\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_vae.fit(x_train,x_train,shuffle=True,\n",
        "              epochs=epochs,\n",
        "              batch_size=batch_size,\n",
        "              validation_data=(x_test, None))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zf8w1JQphdIX",
        "outputId": "19fe77aa-df3a-4647-d793-b341cc5fd09e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "469/469 [==============================] - 10s 19ms/step - loss: 206.8927 - val_loss: 176.5769\n",
            "Epoch 2/10\n",
            "469/469 [==============================] - 7s 15ms/step - loss: 173.2375 - val_loss: 167.3828\n",
            "Epoch 3/10\n",
            "469/469 [==============================] - 8s 18ms/step - loss: 167.7233 - val_loss: 164.7296\n",
            "Epoch 4/10\n",
            "469/469 [==============================] - 7s 15ms/step - loss: 165.1880 - val_loss: 162.4753\n",
            "Epoch 5/10\n",
            "469/469 [==============================] - 8s 17ms/step - loss: 163.3440 - val_loss: 161.2128\n",
            "Epoch 6/10\n",
            "469/469 [==============================] - 7s 15ms/step - loss: 161.8457 - val_loss: 159.9401\n",
            "Epoch 7/10\n",
            "469/469 [==============================] - 8s 17ms/step - loss: 160.5328 - val_loss: 158.7528\n",
            "Epoch 8/10\n",
            "469/469 [==============================] - 7s 16ms/step - loss: 159.3571 - val_loss: 157.6517\n",
            "Epoch 9/10\n",
            "469/469 [==============================] - 8s 17ms/step - loss: 158.3226 - val_loss: 156.7400\n",
            "Epoch 10/10\n",
            "469/469 [==============================] - 8s 16ms/step - loss: 157.4301 - val_loss: 156.1569\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f7d71671300>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#잠재 변수를 얻기 위한 모델\n",
        "encoder = Model(x,z)\n",
        "\n",
        "#훈련 데이터로부터 만든 잠재 변수를 2차원 플롯\n",
        "z_train = encoder.predict(x_train, batch_size=batch_size)\n",
        "plt.figure(figsize=(6,6))\n",
        "plt.scatter(z_train[:,0], z_train[:,1], c=t_train)  #라벨을 색으로 나타낸다\n",
        "plt.title(\"Train\")\n",
        "plt.colorbar()\n",
        "plt.show()\n",
        "\n",
        "#테스트 데이터를 입력해서 잠재 공간에 2차원 플롯한다 > 정답 라벨을 색으로 표시\n",
        "z_test = encoder.predict(x_test, batch_size=batch_size)\n",
        "plt.figure(figsize=(6,6))\n",
        "plt.scatter(z_test[:,0], z_test[:,1], c=t_test)\n",
        "plt.title(\"Test\")\n",
        "plt.colorbar()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "9ambng0rhfRn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#이미지 생성기\n",
        "input_decoder = Input(shape=(n_z,))\n",
        "h_decoder = mid_decoder(input_decoder)\n",
        "y = out_decoder(h_decoder)\n",
        "generator = Model(input_decoder, y)\n",
        "\n",
        "#이미지를 나열하는 설정\n",
        "n = 16   #손으로 쓴 문자 이미지를 16x16 나열한다\n",
        "image_size = 28\n",
        "matrix_image = np.zeros((image_size*n, image_size*n))  #전체 이미지\n",
        "\n",
        "#잠재 변수\n",
        "z_1 = np.linspace(2, -2, n)  #각 행 \n",
        "z_2 = np.linspace(-2, 2, n)  #각 열\n",
        "\n",
        "#잠재 변수를 변화시켜서 이미지 생성\n",
        "for i, z1 in enumerate(z_1):\n",
        "  for j, z2 in enumerate(z_2):\n",
        "    decoded = generator.predict(np.array([[z2,z1]]))  #x축, y축의 순서로 넣는다\n",
        "    image = decoded[0].reshape(image_size, image_size)\n",
        "    matrix_image[i*image_size : (i+1)*image_size, j*image_size: (j+1)*image_size] = image\n",
        "\n",
        "plt.figure(figsize=(10,10))\n",
        "plt.imshow(matrix_image, cmap=\"Greys_r\")\n",
        "plt.tick_params(labelbottom=False, labelleft=False, bottom=False, left=False)  #축 눈금의 라벨과 선을 지운다 \n",
        "plt.show()"
      ],
      "metadata": {
        "id": "vJz8X_-Ghjh1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}